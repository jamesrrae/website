<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>James R. Rae on James R. Rae</title>
    <link>/</link>
    <description>Recent content in James R. Rae on James R. Rae</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 -0400</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Predicting Early Childhood Gender Transitions</title>
      <link>/publication/2019-rae-etal/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 -0500</pubDate>
      
      <guid>/publication/2019-rae-etal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bayesian Logistic Regression using brms, Part 1</title>
      <link>/post/bayesian-logistic-regression-using-brms-part-1/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/bayesian-logistic-regression-using-brms-part-1/</guid>
      <description>


&lt;p&gt;&lt;strong&gt;This is the first of a series of posts on how to fit, interpret, and evaluate Bayesian logistic regression models using the brms package in R. This is a post written with &lt;a href=&#34;https://nilsreimer.com/&#34;&gt;Nils Karl Reimer&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This post provides a gentle introduction to fitting Bayesian logistic regression models using the &lt;code&gt;brms&lt;/code&gt; package in R &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;(Bürkner, 2017)&lt;/a&gt;. Why use &lt;code&gt;brms&lt;/code&gt;? Besides being an excellent package with lots of cool features, the specification of regression models in &lt;code&gt;brms&lt;/code&gt; closely mirrors the syntax you may already use to fit regression models in R, such as with the &lt;code&gt;lm()&lt;/code&gt; or &lt;code&gt;glm()&lt;/code&gt; commands. This should make a first pass at fitting Bayesian logistic regression models easier.&lt;/p&gt;
&lt;p&gt;Before jumping into the tutorial, a couple of caveats: We’re assuming that you have some familiarity with (1) the R statistical computing environment, (2) interpreting logistic regression models, and (3) key concepts in Bayesian statistical analyses. If you need a refresher on R, see &lt;a href=&#34;https://cran.r-project.org/doc/manuals/r-release/R-intro.pdf&#34;&gt;here&lt;/a&gt;. For information on logistic regression, perhaps take a look at this introductory &lt;a href=&#34;https://www.theanalysisfactor.com/introduction-to-logistic-regression/&#34;&gt;tutorial&lt;/a&gt;. If you’d like some background on Bayesian methods and are short on time, We’d suggest this &lt;a href=&#34;https://link.springer.com/article/10.3758/s13423-016-1221-4&#34;&gt;article&lt;/a&gt;. For a more thorough coverage, see &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;McElreath (2017)&lt;/a&gt;, &lt;a href=&#34;https://uk.sagepub.com/en-gb/eur/a-student%E2%80%99s-guide-to-bayesian-statistics/book245409&#34;&gt;Lambert (2018)&lt;/a&gt;, or—if you’re ready for the deep dive—Bayesian Data Analysis by &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/&#34;&gt;Gelman and colleagues (2016)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;OK, let’s dive in!&lt;/p&gt;
&lt;div id=&#34;the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Data&lt;/h2&gt;
&lt;p&gt;We’re going to use some data collected via &lt;a href=&#34;https://implicit.harvard.edu/implicit/&#34;&gt;Project Implicit&lt;/a&gt;—a non-profit organization that operates a virtual laboratory where people can take various versions of the Implicit Association Test (IAT). Project Implicit kindly makes the data from this site publicly available on the &lt;a href=&#34;https://osf.io/y9hiq/&#34;&gt;Open Science Framework&lt;/a&gt;. Anyone can use it (just acknowledge Project Implicit in any publications!) and there’s a lot of it. You should check it out!&lt;/p&gt;
&lt;p&gt;This tutorial uses data from the Sexuality IAT collected during 2017. If you’re not familiar with this particular version of the IAT, it measures someone’s relative preference for straight people over gay people. Scores above zero indicate a preference for straight people over gay people, a score of zero indicates no preference for either group, and scores below zero indicate a preference for gay people over straight people. Specifically, we’re going to look at whether implicit straight/gay attitudes predicts attitude-relevant policy positions.&lt;/p&gt;
&lt;p&gt;The raw data for the Sexuality IAT task is available &lt;a href=&#34;https://osf.io/ctqxo/&#34;&gt;here&lt;/a&gt;. However, Bayesian analyses can be quite computationally intensive. As there is data from over 300,000 respondents in the 2017 data set, we’ll be working with a random draw of 5,000 sessions so it’s less time intensive for you to try these analyses for yourself. We’ve also done some data cleaning and recoding. If you want to see how we derived the data for this example, see &lt;a href=&#34;https://github.com/jamesrrae/sexuality-iat-website-data/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-ready-for-the-analyses&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting Ready for the Analyses&lt;/h2&gt;
&lt;p&gt;First, we’re going to have a couple of packages handy to get started:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms); library(tidyverse); library(tidybayes); library(ggplot2); library(LaplacesDemon)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: package &amp;#39;LaplacesDemon&amp;#39; was built under R version 3.5.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you already know, we’re going to need the &lt;code&gt;brms&lt;/code&gt; package to fit our logistic regression models. Critically, &lt;code&gt;brms&lt;/code&gt; relies on Stan &lt;a href=&#34;https://mc-stan.org/&#34;&gt;(Stan Development Team, 2017)&lt;/a&gt;, which is a great tool for fitting Bayesian analyses. For details on installing Stan, see &lt;a href=&#34;https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started&#34;&gt;here&lt;/a&gt;. Once you’ve done these steps you’ll need to have the &lt;code&gt;brms&lt;/code&gt; library loaded. Another option is to use the free RStudio cloud service—they already have Stan installed. For details, see &lt;a href=&#34;https://andrewgelman.com/2018/10/12/stan-on-the-web-for-free-thanks-to-rstudio/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s read the data into R:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;lrsmall &amp;lt;- read_csv(url(&amp;quot;https://raw.githubusercontent.com/jamesrrae/sexuality-iat-website-data/master/lrsmall.csv&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let’s get a sense of the data:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(lrsmall)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5,000 x 2
##    Allowed     D.z
##      &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
##  1      NA   1.48 
##  2       1   0.976
##  3      NA  NA    
##  4       1   0.568
##  5      NA  NA    
##  6       1   1.08 
##  7       1  -1.68 
##  8       1  -0.507
##  9       1   0.487
## 10      NA   0.174
## # ... with 4,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, so we have two variables that we’ll use for our logistic regression analysis. &lt;code&gt;Allowed&lt;/code&gt; indexes self-reported answers to the question “Do you think it should be legal for same-sex partners to adopt a child?”. We’ll just focus on two response options: 0 = “Should not be legal” and 1 = “Should be legal”. The variable &lt;code&gt;D.z&lt;/code&gt; is standardized IAT scores calculated by subtracting off the mean and dividing by the standard deviation.&lt;/p&gt;
&lt;p&gt;Next, let’s look at the correlation between our two variables. This will help us know what to expect before doing our logistic regression analysis:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor.test(lrsmall$Allowed,lrsmall$D.z)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
##  Pearson&amp;#39;s product-moment correlation
## 
## data:  lrsmall$Allowed and lrsmall$D.z
## t = -13.083, df = 2922, p-value &amp;lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.2691916 -0.2007010
## sample estimates:
##        cor 
## -0.2352383&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variables are negatively correlated at about .20. And this makes sense—people with stronger implicit preferences for straight people over gay people are less likely to report that it’s OK for same-sex couples to adopt.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-brms-for-logistic-regression-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using brms for Logistic Regression Analysis&lt;/h2&gt;
&lt;p&gt;First, we must set some priors for the parameters in our logistic regression model—the intercept and slope. We follow common &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;prior choice recommendations&lt;/a&gt; for the intercept and slope:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[ \beta \sim \text{Student}(3, 0, 2.5) \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This prior is a Student-t distribution (bell-shaped but with fatter tails than a normal distribution) with 3 degrees of freedom, a mean of 0, and scale of 2.5. This is a pretty wide prior. To see why, let’s look at the distribution:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x_values &amp;lt;- seq(-15,15, length.out = 1000)
data.frame(x_values) %&amp;gt;%
ggplot(aes(x_values))+
  stat_function(fun=dst, args=list(nu=3,mu=0,sigma=2.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-logistic-regression-using-brms-part-1_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;As you can see from the figure, this prior roughly expresses an expectation most values to be between -10 and +10. However, as pointed out by &lt;a href=&#34;https://projecteuclid.org/download/pdfview_1/euclid.aoas/1231424214&#34;&gt;Gelman and colleagues (2008)&lt;/a&gt;, even a change from -5 to 0 correspondents to a change on a probability scale of .01 to .50. It would be pretty huge effect if a 1 unit change in &lt;code&gt;D.z&lt;/code&gt; (i.e., a 1 standard deviation difference on the IAT) corresponded to nearly .50 change in the probability of supporting adoption rights for same-sex couples. For further discussion of these priors, see &lt;a href=&#34;https://projecteuclid.org/download/pdfview_1/euclid.aoas/1231424214&#34;&gt;Gelman et al. 2008&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now, let’s specify these priors in a format that brms can use when we run the model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m1priors &amp;lt;- c(
  prior(student_t(3, 0, 2.5), class = &amp;quot;Intercept&amp;quot;),
  prior(student_t(3, 0, 2.5), class = &amp;quot;b&amp;quot;)
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, now we’re finally ready to fit our model (be warned, this could take a bit of time!):&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m1 &amp;lt;- brm(
  Allowed ~ D.z,
  data = lrsmall,
  prior = m1priors,
  family = &amp;quot;bernoulli&amp;quot;,
  seed = 123 # Adding a seed makes results reproducible.
) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Rows containing NAs were excluded from the model.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Compiling the C++ model&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Start sampling&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## SAMPLING FOR MODEL &amp;#39;d59bd52f6c6c61f33001490da41f7746&amp;#39; NOW (CHAIN 1).
## Chain 1: Gradient evaluation took 0 seconds
## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 1: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 1: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 1:  Elapsed Time: 1.872 seconds (Warm-up)
## Chain 1:                1.638 seconds (Sampling)
## Chain 1:                3.51 seconds (Total)
## 
## SAMPLING FOR MODEL &amp;#39;d59bd52f6c6c61f33001490da41f7746&amp;#39; NOW (CHAIN 2).
## Chain 2: Gradient evaluation took 0 seconds
## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Chain 2: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 2: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 2:  Elapsed Time: 1.859 seconds (Warm-up)
## Chain 2:                1.901 seconds (Sampling)
## Chain 2:                3.76 seconds (Total)
## 
## SAMPLING FOR MODEL &amp;#39;d59bd52f6c6c61f33001490da41f7746&amp;#39; NOW (CHAIN 3).
## Chain 3: Gradient evaluation took 0.001 seconds
## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.
## Chain 3: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 3: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 3:  Elapsed Time: 1.909 seconds (Warm-up)
## Chain 3:                1.804 seconds (Sampling)
## Chain 3:                3.713 seconds (Total)
## 
## SAMPLING FOR MODEL &amp;#39;d59bd52f6c6c61f33001490da41f7746&amp;#39; NOW (CHAIN 4).
## Chain 4: Gradient evaluation took 0.001 seconds
## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 10 seconds.
## Chain 4: Iteration:    1 / 2000 [  0%]  (Warmup)
## Chain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)
## Chain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)
## Chain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)
## Chain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)
## Chain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Chain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Chain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Chain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Chain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Chain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Chain 4: Iteration: 2000 / 2000 [100%]  (Sampling)
## Chain 4:  Elapsed Time: 1.848 seconds (Warm-up)
## Chain 4:                1.683 seconds (Sampling)
## Chain 4:                3.531 seconds (Total)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So in the model above, we’ve specified that we’re regressing &lt;code&gt;Allowed&lt;/code&gt; on &lt;code&gt;D.z&lt;/code&gt; using the priors in &lt;code&gt;m1priors&lt;/code&gt;. You’ll also notice that we had to specify a likelihood, which is set by the &lt;code&gt;family&lt;/code&gt; argument. As we had a dichotomous outcome, we set this to &lt;code&gt;&amp;quot;bernoulli&amp;quot;&lt;/code&gt;. Finally, we used a &lt;code&gt;seed&lt;/code&gt; to make the results the same each time we run this particular model.&lt;/p&gt;
&lt;p&gt;Ok, now it’s time to look at the results. First, let’s just look at the summary of out model:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;summary(m1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: bernoulli 
##   Links: mu = logit 
## Formula: Allowed ~ D.z 
##    Data: lrsmall (Number of observations: 2924) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept     2.96      0.10     2.77     3.17       1346 1.00
## D.z          -1.07      0.09    -1.26    -0.89       1271 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First of all, this summary provides some really useful information about the model, including the number of observations, chains, and iterations. For a more thorough description of this information, see the &lt;code&gt;brms&lt;/code&gt; manual &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/brms.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’re just getting started with Bayesian data analysis, the most familiar information is going to be under the heading &lt;code&gt;Population-Level Effects&lt;/code&gt;. Here you’ll find summary information about the regression slope and intercept. First of all, the &lt;code&gt;Rhat&lt;/code&gt; values near 1.0 indicates that we have convergence. If &lt;code&gt;Rhat&lt;/code&gt; values get too large (see &lt;a href=&#34;https://blog.stata.com/2016/05/26/gelman-rubin-convergence-diagnostic-using-multiple-chains/&#34;&gt;here&lt;/a&gt; for a suggestion of 1.2 or 1.1) then we should be worried. Second, we see that the most credible values of the slope are negative, which is good because above we observed that &lt;code&gt;D.z&lt;/code&gt; was negatively correlated with &lt;code&gt;Allowed&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So while our logistic regression model indicates that there is a negative relationship between &lt;code&gt;Allowed&lt;/code&gt; and &lt;code&gt;D.z&lt;/code&gt;, the summary of the model has estimates on the log-odds scale, which can be difficult to interpret. So let’s use the &lt;code&gt;tidybayes&lt;/code&gt; package &lt;a href=&#34;http://mjskay.github.io/tidybayes/&#34;&gt;(Kay, 2018)&lt;/a&gt; to put our results on the odds scale:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters &amp;lt;- m1 %&amp;gt;% gather_draws(b_D.z) %&amp;gt;% median_hdi()
print(exp(parameters[c(&amp;quot;.value&amp;quot;,&amp;quot;.lower&amp;quot;,&amp;quot;.upper&amp;quot;)])) # exp() converts log-odds to odds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   .value .lower .upper
##    &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1  0.343  0.287  0.412&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On the odds scale, we are comparing our estimate to 1.0. If the most credible value of the slope is mostly below 1.0, then we infer that there’s a negative association between &lt;code&gt;Allowed&lt;/code&gt; and &lt;code&gt;D.z&lt;/code&gt;. This is the case here as we are 95% sure (given the data and the model) that the slope is roughly between .28 and .40.&lt;/p&gt;
&lt;p&gt;Finally, let’s make a basic plot that shows the model predictions. Conveniently, &lt;code&gt;brms&lt;/code&gt; has a command that makes this quite easy:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(marginal_effects(m1), points = TRUE, rug = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-logistic-regression-using-brms-part-1_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows the predicted probability of supporting adoption for same-sex couples at different levels of &lt;code&gt;D.z&lt;/code&gt;. First, notice that for values below zero on the x-axis (i.e., below the mean IAT score) the support of this policy is quite high: near 1.0. Then, notice that the probability of supporting adoption right for same-sex couples drops, eventually bottoming out at about .50 for those respondents that have the strongest preference for straight people over gay people. Finally, while these are less useful when dealing with a large sample like we’re using here, the &lt;code&gt;points&lt;/code&gt; and &lt;code&gt;rug&lt;/code&gt; arguments plot the data data alongside the model predictions. You can see from the black dots show responses on the &lt;code&gt;Allowed&lt;/code&gt; variable (either 0 or 1), while the black vertical lines at the bottom of the plot show scores on the &lt;code&gt;D.z&lt;/code&gt; variable. These additional features are helpful for making sure that the model is providing a sensible fit to the data.&lt;/p&gt;
&lt;p&gt;Ok, so that’s a basic logistic regression model using brms. Future posts might address some of the issues that we didn’t touch on here, such as what to do about missing data? How to create publication-worthy logistic regression plots? And what additional model assessments can we do with &lt;code&gt;brms&lt;/code&gt;?&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Example Page</title>
      <link>/tutorial/example/</link>
      <pubDate>Sun, 09 Sep 2018 00:00:00 -0400</pubDate>
      
      <guid>/tutorial/example/</guid>
      <description>

&lt;p&gt;In this tutorial, I&amp;rsquo;ll share my top 10 tips for getting started with Academic:&lt;/p&gt;

&lt;h2 id=&#34;tip-1&#34;&gt;Tip 1&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;tip-2&#34;&gt;Tip 2&lt;/h2&gt;

&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Prejudice, Contact, and Threat at the Diversity-Segregation Nexus: A Cross-Sectional and Longitudinal Analysis of How Ethnic Out-Group Size and Segregation Interrelate for Inter-Group Relations</title>
      <link>/publication/2018-laurence-schmid-rae-hewstone/</link>
      <pubDate>Wed, 15 Aug 2018 00:00:00 -0400</pubDate>
      
      <guid>/publication/2018-laurence-schmid-rae-hewstone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 -0400</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>A Robust Bias Against Interracial Couples Among White and Black Respondents, Relative to Multiracial Respondents</title>
      <link>/publication/2018-skinner-rae/</link>
      <pubDate>Wed, 20 Jun 2018 00:00:00 -0400</pubDate>
      
      <guid>/publication/2018-skinner-rae/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Test-Retest Reliability and Predictive Validity of the Implicit Association Test in Children</title>
      <link>/publication/2018-rae-olson/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 -0500</pubDate>
      
      <guid>/publication/2018-rae-olson/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Persons or Situations? Individual Differences Explain Variance in Aggregated Implicit Race Attitudes</title>
      <link>/publication/2017-rae-greenwald/</link>
      <pubDate>Thu, 30 Nov 2017 00:00:00 -0500</pubDate>
      
      <guid>/publication/2017-rae-greenwald/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Client-Level Session-by-Session Evaluation of Behavioral Activation&#39;s Mechanism of Action</title>
      <link>/publication/2017-santos-etal/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 -0500</pubDate>
      
      <guid>/publication/2017-santos-etal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>/talk/example/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 -0500</pubDate>
      
      <guid>/talk/example/</guid>
      <description>&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;Click on the &lt;strong&gt;Slides&lt;/strong&gt; button above to view the built-in slides feature.&lt;/p&gt;

&lt;/div&gt;


&lt;p&gt;Slides can be added in a few ways:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Create&lt;/strong&gt; slides using Academic&amp;rsquo;s &lt;em&gt;Slides&lt;/em&gt; feature and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Upload&lt;/strong&gt; an existing slide deck to &lt;code&gt;static/&lt;/code&gt; and link using &lt;code&gt;url_slides&lt;/code&gt; parameter in the front matter of the talk file&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Embed&lt;/strong&gt; your slides (e.g. Google Slides) or presentation video on this page using &lt;a href=&#34;https://sourcethemes.com/academic/docs/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Further talk details can easily be added to this page using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>External Project</title>
      <link>/project/external-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0400</pubDate>
      
      <guid>/project/external-project/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Internal Project</title>
      <link>/project/internal-project/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 -0400</pubDate>
      
      <guid>/project/internal-project/</guid>
      <description>&lt;p&gt;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.&lt;/p&gt;

&lt;p&gt;Nullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.&lt;/p&gt;

&lt;p&gt;Cras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.&lt;/p&gt;

&lt;p&gt;Suspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.&lt;/p&gt;

&lt;p&gt;Aliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reinforcement Matters: A preliminary, Laboratory-Based Component-Process Analysis of Functional Analytic Psychotherapy&#39;s Model of Social Connection</title>
      <link>/publication/2015-haworth-etal/</link>
      <pubDate>Thu, 01 Oct 2015 00:00:00 -0400</pubDate>
      
      <guid>/publication/2015-haworth-etal/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Exposure to Racial Out-Groups and Implicit Race Bias in the United States</title>
      <link>/publication/2015-rae-newheiser-olson/</link>
      <pubDate>Wed, 01 Jul 2015 00:00:00 -0400</pubDate>
      
      <guid>/publication/2015-rae-newheiser-olson/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Do Motivations for using Facebook Moderate the Association between Facebook use and Psychological Well-Being?</title>
      <link>/publication/2015-rae-lonborg/</link>
      <pubDate>Fri, 12 Jun 2015 00:00:00 -0400</pubDate>
      
      <guid>/publication/2015-rae-lonborg/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
